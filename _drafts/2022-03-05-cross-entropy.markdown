---
layout: post
title:  "Cross Entropy"
date:   2022-03-05 14:01:45 -0700
categories: Mathematics
---

> In information theory, the cross-entropy between two probability distributions p and q over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set if a coding scheme used for the set is optimized for an estimated probability distribution q, rather than the true distribution p.

Cross Entropy, often associated with "Categorical Cross Entropy" is a technique frequently used in machine learning to 
maximize optimization betwen two probabilty distributions. 


